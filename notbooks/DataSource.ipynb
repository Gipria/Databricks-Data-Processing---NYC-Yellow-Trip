{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaff6b50-7a62-47a9-8c78-8fb968325552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, lit, col, to_timestamp, unix_timestamp, current_timestamp\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import min as spark_min, max as spark_max\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1f0ecf6-219d-4b86-af29-3e87dde4b13c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df = spark.table(\"yellow_trip_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44e0aa8-2512-435c-9b33-24b2313cc9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_unique = raw_df.dropDuplicates() # nao tem duplicadas eu ja verifiquei\n",
    "df = df_unique.withColumn(\"_id\", monotonically_increasing_id())\n",
    "\n",
    "#timestamp\n",
    "\n",
    "df = df.withColumn(\"tpep_pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\", \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\")).withColumn(\"tpep_dropoff_datetime\", to_timestamp(\"tpep_dropoff_datetime\", \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"))\n",
    "\n",
    "df = df.withColumn(\"processing_date\", current_timestamp())\n",
    "\n",
    "#range data correta\n",
    "df_invalid_date = df.filter(\n",
    "    (col(\"tpep_pickup_datetime\") < lit(\"2023-01-01\")) &\n",
    "    (col(\"tpep_pickup_datetime\") > lit(\"2023-04-30\"))\n",
    ")\n",
    "df = df.subtract(df_invalid_date)\n",
    "\n",
    "# retirando itens com horas inconsistentes | tirar viagens com menos de 1 minuto \n",
    "df_inconsistent_time = df.filter(col(\"tpep_pickup_datetime\") > col(\"tpep_dropoff_datetime\"))\n",
    "#df = df.filter(col(\"tpep_pickup_datetime\") <= col(\"tpep_dropoff_datetime\"))\n",
    "df = df.subtract(df_inconsistent_time)\n",
    "\n",
    "df = df.withColumn(\"pickup_seconds\", unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))).filter(col(\"pickup_seconds\") >= 60)\n",
    "df_invalid_duration = df.filter(col(\"pickup_seconds\") < 60)\n",
    "\n",
    "# Filtro validando se algum sai da delimitacao das cidades estabelecidas\n",
    "df = df.filter(\"PULocationID >= 1 AND PULocationID <= 265 AND DOLocationID >= 1 AND DOLocationID <= 265\")\n",
    "df_invalid_location = df.filter(\"PULocationID < 1 OR PULocationID > 265 OR DOLocationID < 1 OR DOLocationID > 265\")\n",
    "\n",
    "\n",
    "\n",
    "# Filtro passageiros (nao pode ser 0 ou maior igual a 5)\n",
    "df = df.filter((col(\"passenger_count\") >= 1) & (col(\"passenger_count\") <= 4))\n",
    "df_invalid_passengers = df.filter((col(\"passenger_count\") < 1) | (col(\"passenger_count\") > 4))\n",
    "\n",
    "# trip distance nao pode ser 0\n",
    "df = df.filter(col(\"trip_distance\") > 0)\n",
    "df_invalid_distance = df.filter(col(\"trip_distance\") <= 0)\n",
    "\n",
    "# fire_amount nao pode ser 0\n",
    "df = df.filter(col(\"fare_amount\") > 0)\n",
    "df_invalid_fare = df.filter(col(\"fare_amount\") <= 0)\n",
    "\n",
    "#payment_type no range estabelecido\n",
    "df = df.filter((col(\"payment_type\") >= 1) & (col(\"payment_type\") <= 6))\n",
    "df_invalid_payment = df.filter((col(\"payment_type\") < 1) | (col(\"payment_type\") > 6))\n",
    "\n",
    "# vendorID == nulo \n",
    "df = df.filter(col(\"VendorID\").isNotNull() & (col(\"VendorID\").isin([1,2,6,7])))\n",
    "df_invalid_vendor = df.filter(col(\"VendorID\").isNull() | (~col(\"VendorID\").isin([1,2,6,7])))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"is_outlier\",\n",
    "    (col(\"trip_distance\") > 100) | (col(\"fare_amount\") > 500) | (col(\"fare_amount\")/col(\"trip_distance\") < 0.5)\n",
    ")\n",
    "\n",
    "# Invalid Data\n",
    "df_invalid = df_invalid_date.unionByName(df_inconsistent_time, allowMissingColumns=True).unionByName(df_invalid_location, allowMissingColumns=True).unionByName(df_invalid_passengers, allowMissingColumns=True).unionByName(df_invalid_distance, allowMissingColumns=True).unionByName(df_invalid_fare, allowMissingColumns=True).unionByName(df_invalid_payment, allowMissingColumns=True).unionByName(df_invalid_vendor, allowMissingColumns=True)\n",
    "\n",
    "df_invalid.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"yellow_trip_silver_invalid\")\n",
    "\n",
    "\n",
    "df.filter(col(\"is_outlier\") == True)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"yellow_trip_silver\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Source",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
